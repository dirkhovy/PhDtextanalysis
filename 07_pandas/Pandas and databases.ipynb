{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# this just tells the notebook to display images in the cells, rather than send it to a new window\n",
    "try:\n",
    "    # library for nicer visualizations\n",
    "    import seaborn\n",
    "    seaborn.set_context('poster')\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas and Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## *'If you torture the data long enough, it will confess.'*\n",
    "*â€“ Master Turtle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Databases are collections of **tables**, organized into **columns** and **rows**, that allow us to store, select, and relate data to each other. The most common language is SQL, which comes in various forms.\n",
    "\n",
    "`pandas` is a library (i.e., a code collection) of useful functions and objects to work with data. It can read from a variety of formats (CSV, Excel, ...), including SQL databases, and has a load of nifty tools to analyze and visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selecting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In SQL, keywords are typically written in CAPS, as to distinguish them from variable names. The general command to get data from a DB is\n",
    "\n",
    "```sql\n",
    "SELECT <columns> FROM <table>\n",
    "```\n",
    "\n",
    "`<columns>` is a comma separated list of the column names we want. If we want **all** columns, we can use the Kleene star `*`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DISTINCT\n",
    "\n",
    "If we want unique entries, we can use the `DISTINCT` keyword:\n",
    "```sql\n",
    "SELECT DISTINCT <columns> FROM <table>\n",
    "```\n",
    "\n",
    "This automatically gets rid of duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### WHERE\n",
    "\n",
    "If we want only entries that fulfill a certain condition, we can use the `WHERE` keyword:\n",
    "```sql\n",
    "SELECT <columns> FROM <table> WHERE <condition>\n",
    "```\n",
    "\n",
    "`<condition>` is similar to a boolean statement in Python, but you don't need double equals for comparison. \n",
    "\n",
    "```sql\n",
    "SELECT * FROM tweets WHERE followers > 100\n",
    "```\n",
    "\n",
    "You can also combine several conditions with `AND` and `OR`.\n",
    "\n",
    "```sql\n",
    "SELECT * FROM tweets WHERE followers > 100 AND is_retweet = 'False'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LIMIT\n",
    "\n",
    "Databases can be massive (that's kind of their point), so when you only want a bit to explore first, use the `LIMIT` keyword:\n",
    "```sql\n",
    "SELECT <columns> FROM <table> LIMIT <N>\n",
    "```\n",
    "\n",
    "`<N>` is the maximum number of entries you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Activity\n",
    "\n",
    "Suppose you have a table called `movies` with the following columns:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>name</th>\n",
    "        <th>director</th>\n",
    "        <th>year</th>\n",
    "        <th>cost</th> \n",
    "        <th>gain</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "How would you select\n",
    "* the unique names of all the directors?\n",
    "* all rows with films made in 1992?\n",
    "* all films made before 2010 that cost under 10M?\n",
    "* the top 10 films made in 2001 that made over 10M?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Databases in Python\n",
    "\n",
    "In order to use SQL in Python, we need a library called `sqlite3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 # this library allows us to connect to a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to establish a connection to the database. We use the `connect()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('../data/example.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Databases can contain several **tables**, so before we proceed, it's a good idea to check how many we have and how they are called. To do this, we first need a **cursor** (think of it as an iterator over the table), and then execute an **SQL command**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # import pandas, but give it a shorthand name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "`pandas` let's us read a table directly into Python. We just need a connection and a SQL command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM reviews\", con=con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this process is a new object, called a **`DataFrame`**. You can think of it as a table on steroids.\n",
    "\n",
    "`pandas` can read all kinds of *X*-separated files (using `read_csv()`), as well as Excel (`read_excel`).\n",
    "\n",
    "By default, `read_csv()` uses commas `,` as separators, but we can tell it to use any other separator, for example tabs `\\t` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can look at the data. The file is rather big, so we will only look at the top 5 lines. We use the `head()` function for it.\n",
    "\n",
    "The top row contains the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at more lines, you need to give that number to the function as argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the bottom rows, with `tail()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Activity: Loading data\n",
    "\n",
    "* create a new variable, `scores`, and read in the distinct scores from the SQL table\n",
    "* look at the last 3 lines of `scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns\n",
    "\n",
    "DataFrames, as well as databases, are organized in columns with names. To get an overview, use the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To see just one column, access it with the same square bracket notation as for lists `[]`. However, rather than a number, use the column name string.\n",
    "\n",
    "Alternatively, you can treat the name like an attribute of the `DataFrame`, and use a dot operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary-style indexing\n",
    "texts1 = df['text']\n",
    "\n",
    "# Alternative syntax\n",
    "texts2 = df.text\n",
    "\n",
    "# check whether the Series are the same\n",
    "print(texts1 is texts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The column returned from such an indexing is called a `Series` object.\n",
    "\n",
    "To select several columns, we need to use the first method, and give it a list of column names. This returns a new `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.text))\n",
    "print(type(df[['text', 'score']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Series functions\n",
    "\n",
    "There are a lot of functions to analyze a `Series` object. One of the most useful is `describe()`, which gives us some descriptive statistics. Some of the ones used here, like `count()`, `mean()`, `max()`, and `min()` can be called by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Acticvity\n",
    "\n",
    "* what are the mean and median of the `age` column?\n",
    "* what do you get when you use describe on a column with strings, like `text` or `gender`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Rows\n",
    "\n",
    "Retrieving a row is also possible, but uses a different method, `iloc` (for **i**nteger **loc**ation), and the index of the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As with lists, you can also use slices, and even lists of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.text.iloc[2:4])\n",
    "print(df.text.iloc[[1,1,5,11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adding new columns\n",
    "\n",
    "Let's create a new column `ratio`, i.e., the amount of score per year of age, based on the existing columns `score` and `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = (df.score / df.age)\n",
    "df.ratio.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Getting rid of outliers\n",
    "\n",
    "## Masks\n",
    "\n",
    "Say we want to remove all ratios below a certain threshold.\n",
    "\n",
    "In dataframes, we can select all the data that matches a certain condition, similar to an SQL table. We can do that with a simple boolean statement. The result is a `Series` object with boolean values, also called a **mask**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_low = df.ratio < 0.1\n",
    "print(too_low.head())\n",
    "print(type(too_low))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Activity\n",
    "\n",
    "* add another, boolean, column to `df`, that signals whether the entry contains the word `price`. Call the new column `has_price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can combine several conditions with the `&` or `|` operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over50 = df.age >= 0\n",
    "\n",
    "print(len(df), len(df[too_low | over50]), len(df[too_low & over50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we apply this mask to our DataFrame, we get *only* the rows where the condition is `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[too_low & over50].iloc[[1, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The value for `ratio`, `NaN`, stands for \"**N**ot **a** **N**umber\". Luckily, we can replace that value with `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan = df.fillna('THIS WAS NAN')\n",
    "df_no_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## apply()\n",
    "\n",
    "Let's also get rid of the `inf` values. We write a simple function that sets them to `0` and `apply` that function to our `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x > 65:\n",
    "        return 'retired'\n",
    "    else:\n",
    "        return 'not_retired'\n",
    "    \n",
    "df_no_nan['status'] = df_no_nan.age.copy().apply(f)\n",
    "df_no_nan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "`pandas` `DataFrame`s have built-in visualization methods under the property `plot`. To get a histogram of the ratios, we can call `hist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan.age.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to get a different representation, let's define the size of each `bin`. Adding `;` at the end of the line prevents the output of the `<matplotlib.axes._subplots.AxesSubplot at 0x118903320>` text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan.age.hist(bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can even separate the plots by another column, for example `gender`, using the keyword `by`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan.age.hist(by=df_no_nan.gender, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Looks similar, but at different scales. To make the y-axis equivalent, use `sharey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan.age.hist(by=df_no_nan.gender, bins=20, sharey=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scatterplotting\n",
    "\n",
    "If we are interested in more than one column, we might want to use the general `plot` method, and the `scatter` function. We need to define the `x` and `y` dimensions by giving a column name from our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan.plot.scatter(x='age', y ='ratio', s=100, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To separate the two categories, you need to \n",
    "* make the first one a variable\n",
    "* pass the variable to the second via `ax`\n",
    "* set different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "axis = df_no_nan[df_no_nan.category == 'Gambling'].plot.scatter(x='age', y ='score', color='teal', s=100, alpha=0.5);\n",
    "df_no_nan[df_no_nan.category == 'Sport'].plot.scatter(x='age', y ='score', color='darkred', ax=axis, s=100, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many more plotting options, see [https://pandas.pydata.org/pandas-docs/stable/visualization.html](https://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "\n",
    "For more on visualizations in general, see [http://serialmentor.com/dataviz/](http://serialmentor.com/dataviz/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Correlations\n",
    "\n",
    "The scatter plot suggested that there is some correlation in the data. Let's check. Luckily, there's a function for that: `corr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan[['age', 'score', 'ratio']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Views\n",
    "\n",
    "We can subselect a number of columns via slicing (a *view*) and put them in a new `DataFrame`by using `copy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_view = df_no_nan[['age', 'score', 'category', 'text']].copy()\n",
    "new_view.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grouping\n",
    "\n",
    "We can group our data by columns. This is useful for example in visualization. Rather than showing two plots as before, we can overlay them (we use `alpha` to set the transparency):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_view[:1000].groupby('category').score.hist(bins=20, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get aggregate statistics for the groups. We use `groupby()`, and then specify how to aggregate the data. Possible aggregators are\n",
    "* `sum()`\n",
    "* `count()`\n",
    "* `min()`\n",
    "* `max()`\n",
    "* `mean()`\n",
    "* `median()`\n",
    "\n",
    "... and many more. See [https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/](https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/) for more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
