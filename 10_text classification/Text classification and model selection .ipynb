{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "countries = {'Italy', 'France', 'Spain', 'Germany', 'US'}\n",
    "wine = pd.read_excel('../data/wine_reviews.xlsx', encoding='utf8')\n",
    "data = wine[wine.country.isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "# shuffle the data\n",
    "data = data[data['description_cleaned'].isna() == False]\n",
    "data = data.sample(frac=1)[:20000]\n",
    "\n",
    "N = len(data)\n",
    "train_size = int(N*0.5)\n",
    "dev_size = int(N*0.25)\n",
    "test_size = int(N*0.25)\n",
    "\n",
    "train = data[:train_size]\n",
    "dev = data[train_size: train_size+dev_size]\n",
    "test = data[train_size+dev_size:]\n",
    "print(len(train), len(dev), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66165</th>\n",
       "      <td>66165</td>\n",
       "      <td>66167</td>\n",
       "      <td>US</td>\n",
       "      <td>This is supersaturated, dense and decadent wit...</td>\n",
       "      <td>Lachini Vineyard</td>\n",
       "      <td>93</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sineann</td>\n",
       "      <td>be supersaturat dense decadent sweet jammy bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51326</th>\n",
       "      <td>51326</td>\n",
       "      <td>51328</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Here's a fresh style of Barbera with bright fr...</td>\n",
       "      <td>Rubia</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Piedmont</td>\n",
       "      <td>Barbera del Monferrato</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barbera</td>\n",
       "      <td>Bottazza</td>\n",
       "      <td>here be fresh style bright fruit note that rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>25484</td>\n",
       "      <td>25486</td>\n",
       "      <td>US</td>\n",
       "      <td>This is made from declassified barrels origina...</td>\n",
       "      <td>YesOuiSi Red</td>\n",
       "      <td>87</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Yakima Valley</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>Red Blend</td>\n",
       "      <td>Stevens</td>\n",
       "      <td>be make declassify barrel originally intend be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140557</th>\n",
       "      <td>140557</td>\n",
       "      <td>140562</td>\n",
       "      <td>US</td>\n",
       "      <td>Super-rich in tropical fruit, pineapple, apric...</td>\n",
       "      <td>Gravelstone</td>\n",
       "      <td>84</td>\n",
       "      <td>13.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Monterey</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Jekel</td>\n",
       "      <td>super rich tropical fruit pineapple apricot pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109352</th>\n",
       "      <td>109352</td>\n",
       "      <td>109355</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Light as a feather and delicately fragrant, th...</td>\n",
       "      <td>Extra Dry</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>Prosecco di Conegliano e Valdobbiadene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prosecco</td>\n",
       "      <td>Vettori</td>\n",
       "      <td>light feather delicately fragrant luminous be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1 country  \\\n",
       "66165        66165         66167      US   \n",
       "51326        51326         51328   Italy   \n",
       "25484        25484         25486      US   \n",
       "140557      140557        140562      US   \n",
       "109352      109352        109355   Italy   \n",
       "\n",
       "                                              description       designation  \\\n",
       "66165   This is supersaturated, dense and decadent wit...  Lachini Vineyard   \n",
       "51326   Here's a fresh style of Barbera with bright fr...             Rubia   \n",
       "25484   This is made from declassified barrels origina...      YesOuiSi Red   \n",
       "140557  Super-rich in tropical fruit, pineapple, apric...       Gravelstone   \n",
       "109352  Light as a feather and delicately fragrant, th...         Extra Dry   \n",
       "\n",
       "        points  price    province                                region_1  \\\n",
       "66165       93   42.0      Oregon                       Willamette Valley   \n",
       "51326       86    NaN    Piedmont                  Barbera del Monferrato   \n",
       "25484       87   18.0  Washington                           Yakima Valley   \n",
       "140557      84   13.0  California                                Monterey   \n",
       "109352      87    NaN      Veneto  Prosecco di Conegliano e Valdobbiadene   \n",
       "\n",
       "                 region_2     variety    winery  \\\n",
       "66165   Willamette Valley  Pinot Noir   Sineann   \n",
       "51326                 NaN     Barbera  Bottazza   \n",
       "25484     Columbia Valley   Red Blend   Stevens   \n",
       "140557      Central Coast  Chardonnay     Jekel   \n",
       "109352                NaN    Prosecco   Vettori   \n",
       "\n",
       "                                      description_cleaned  \n",
       "66165   be supersaturat dense decadent sweet jammy bla...  \n",
       "51326   here be fresh style bright fruit note that rec...  \n",
       "25484   be make declassify barrel originally intend be...  \n",
       "140557  super rich tropical fruit pineapple apricot pe...  \n",
       "109352  light feather delicately fragrant luminous be ...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Germany' 'Italy' 'Spain' 'US']\n",
      "66165         US\n",
      "51326      Italy\n",
      "25484         US\n",
      "140557        US\n",
      "109352     Italy\n",
      "34579         US\n",
      "5565      France\n",
      "99077      Italy\n",
      "138572    France\n",
      "97623         US\n",
      "Name: country, dtype: object [4 4 0 3 4 4 4 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = 'country'\n",
    "\n",
    "# transform labels into numbers\n",
    "labels2numbers = LabelEncoder()\n",
    "\n",
    "y_train = labels2numbers.fit_transform(train[target])\n",
    "\n",
    "print(labels2numbers.classes_)\n",
    "print(data[target][:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Italy', 'Spain', 'US'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2numbers.inverse_transform([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dev and test with the same label converter\n",
    "y_dev = labels2numbers.transform(dev[target])\n",
    "y_test = labels2numbers.transform(test[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the label distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 0.5318,\n",
       " 'Italy': 0.1992,\n",
       " 'France': 0.1789,\n",
       " 'Spain': 0.0702,\n",
       " 'Germany': 0.0199}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "{labels2numbers.classes_[k]: v/len(y_train) for k, v in Counter(y_train).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Italy': 0.204,\n",
       " 'US': 0.5186,\n",
       " 'France': 0.18,\n",
       " 'Germany': 0.0208,\n",
       " 'Spain': 0.0766}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{labels2numbers.classes_[k]: v/len(y_dev) for k, v in Counter(y_dev).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 0.5422,\n",
       " 'Italy': 0.1898,\n",
       " 'France': 0.185,\n",
       " 'Germany': 0.0186,\n",
       " 'Spain': 0.0644}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{labels2numbers.classes_[k]: v/len(y_test) for k, v in Counter(y_test).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4938)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
    "                             min_df=0.001, \n",
    "                             max_df=0.7, \n",
    "                             analyzer='word')\n",
    "\n",
    "X_train = vectorizer.fit_transform(train['description_cleaned'])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4938) (5000, 4938)\n"
     ]
    }
   ],
   "source": [
    "X_dev = vectorizer.transform(dev['description_cleaned'])\n",
    "X_test = vectorizer.transform(test['description_cleaned'])\n",
    "print(X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       900\n",
      "           1       0.00      0.00      0.00       104\n",
      "           2       0.00      0.00      0.00      1020\n",
      "           3       0.00      0.00      0.00       383\n",
      "           4       0.52      1.00      0.68      2593\n",
      "\n",
      "    accuracy                           0.52      5000\n",
      "   macro avg       0.10      0.20      0.14      5000\n",
      "weighted avg       0.27      0.52      0.35      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dirkhovy/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "most_frequent = DummyClassifier(strategy='most_frequent')\n",
    "most_frequent.fit(X_train, y_train)\n",
    "dumb_predictions = most_frequent.predict(X_dev)\n",
    "\n",
    "print(classification_report(y_dev, dumb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.4 ms, sys: 156 ms, total: 224 ms\n",
      "Wall time: 5.58 s\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs')\n",
    "%time classifier.fit(X_train, y_train)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86       900\n",
      "           1       0.72      0.12      0.21       104\n",
      "           2       0.94      0.90      0.92      1020\n",
      "           3       0.88      0.70      0.78       383\n",
      "           4       0.86      0.98      0.92      2593\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.87      0.70      0.74      5000\n",
      "weighted avg       0.89      0.89      0.88      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_dev)\n",
    "print(classification_report(y_dev,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A better classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.7 ms, sys: 130 ms, total: 188 ms\n",
      "Wall time: 1.9 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       900\n",
      "           1       0.42      0.82      0.56       104\n",
      "           2       0.92      0.92      0.92      1020\n",
      "           3       0.74      0.92      0.82       383\n",
      "           4       0.96      0.90      0.93      2593\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.78      0.88      0.82      5000\n",
      "weighted avg       0.91      0.89      0.90      5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       925\n",
      "           1       0.40      0.75      0.52        93\n",
      "           2       0.90      0.93      0.91       949\n",
      "           3       0.71      0.90      0.79       322\n",
      "           4       0.95      0.89      0.92      2711\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.77      0.87      0.80      5000\n",
      "weighted avg       0.90      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_balanced = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
    "                                         class_weight='balanced')\n",
    "%time classifier_balanced.fit(X_train, y_train)\n",
    "predictions_balanced = classifier_balanced.predict(X_dev)\n",
    "\n",
    "print(classification_report(y_dev, predictions_balanced))\n",
    "\n",
    "predictions_balanced_test = classifier_balanced.predict(X_test)\n",
    "print(classification_report(y_test, predictions_balanced_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "New best performance: 0.9068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       900\n",
      "           1       0.52      0.62      0.57       104\n",
      "           2       0.93      0.92      0.92      1020\n",
      "           3       0.82      0.87      0.84       383\n",
      "           4       0.94      0.94      0.94      2593\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.82      0.84      0.83      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "20\n",
      "New best performance: 0.9103999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       900\n",
      "           1       0.52      0.65      0.58       104\n",
      "           2       0.93      0.92      0.93      1020\n",
      "           3       0.81      0.89      0.85       383\n",
      "           4       0.94      0.94      0.94      2593\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.82      0.85      0.83      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       900\n",
      "           1       0.52      0.68      0.59       104\n",
      "           2       0.93      0.92      0.93      1020\n",
      "           3       0.80      0.90      0.85       383\n",
      "           4       0.95      0.93      0.94      2593\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.82      0.86      0.84      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       900\n",
      "           1       0.50      0.71      0.58       104\n",
      "           2       0.93      0.92      0.93      1020\n",
      "           3       0.79      0.90      0.84       383\n",
      "           4       0.95      0.93      0.94      2593\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.81      0.87      0.83      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       900\n",
      "           1       0.45      0.75      0.57       104\n",
      "           2       0.92      0.92      0.92      1020\n",
      "           3       0.76      0.91      0.83       383\n",
      "           4       0.95      0.91      0.93      2593\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.80      0.87      0.82      5000\n",
      "weighted avg       0.91      0.90      0.90      5000\n",
      "\n",
      "\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       900\n",
      "           1       0.38      0.86      0.53       104\n",
      "           2       0.91      0.91      0.91      1020\n",
      "           3       0.71      0.92      0.80       383\n",
      "           4       0.96      0.89      0.92      2593\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.77      0.88      0.80      5000\n",
      "weighted avg       0.90      0.88      0.89      5000\n",
      "\n",
      "\n",
      "0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       900\n",
      "           1       0.28      0.91      0.43       104\n",
      "           2       0.87      0.89      0.88      1020\n",
      "           3       0.62      0.89      0.73       383\n",
      "           4       0.96      0.82      0.88      2593\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.71      0.86      0.75      5000\n",
      "weighted avg       0.88      0.84      0.85      5000\n",
      "\n",
      "\n",
      "0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       900\n",
      "           1       0.25      0.91      0.39       104\n",
      "           2       0.86      0.89      0.88      1020\n",
      "           3       0.60      0.89      0.72       383\n",
      "           4       0.96      0.79      0.87      2593\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.70      0.86      0.73      5000\n",
      "weighted avg       0.87      0.82      0.84      5000\n",
      "\n",
      "\n",
      "0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78       900\n",
      "           1       0.19      0.92      0.31       104\n",
      "           2       0.85      0.87      0.86      1020\n",
      "           3       0.55      0.87      0.68       383\n",
      "           4       0.97      0.70      0.82      2593\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.66      0.83      0.69      5000\n",
      "weighted avg       0.86      0.77      0.80      5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "best_c = None\n",
    "best_performance = 0.0\n",
    "\n",
    "for c in [50, 20, 10, 5, 2, 0.5, 0.1, 0.05, 0.01]:\n",
    "    print(c)\n",
    "    classifier_c = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
    "                                             class_weight='balanced',\n",
    "                                             C=c\n",
    "                                     )\n",
    "    classifier_c.fit(X_train, y_train)\n",
    "    predictions_c = classifier_c.predict(X_dev)\n",
    "    score = f1_score(y_dev, predictions_c, average='micro')\n",
    "    if score > best_performance:\n",
    "        best_performance = score\n",
    "        best_c = c\n",
    "        print(\"New best performance: {}\".format(score))\n",
    "        \n",
    "    print(classification_report(y_dev, predictions_c))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       925\n",
      "           1       0.49      0.53      0.51        93\n",
      "           2       0.92      0.93      0.92       949\n",
      "           3       0.79      0.88      0.83       322\n",
      "           4       0.94      0.93      0.94      2711\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.81      0.83      0.82      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_c = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
    "                                         class_weight='balanced',\n",
    "                                         C=best_c\n",
    "                                 )\n",
    "classifier_c.fit(X_train, y_train)\n",
    "\n",
    "predictions_c_dev = classifier_c.predict(X_dev)\n",
    "predictions_c_test = classifier_c.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_c_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4500) (5000, 4500) (5000, 4500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k=4500).fit(X_train, y_train)\n",
    "\n",
    "X_train_sel = selector.transform(X_train)\n",
    "X_dev_sel = selector.transform(X_dev)\n",
    "X_test_sel = selector.transform(X_test)\n",
    "\n",
    "print(X_train_sel.shape, X_dev_sel.shape, X_test_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       900\n",
      "           1       0.43      0.85      0.57       104\n",
      "           2       0.92      0.92      0.92      1020\n",
      "           3       0.73      0.92      0.82       383\n",
      "           4       0.96      0.90      0.93      2593\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.78      0.89      0.82      5000\n",
      "weighted avg       0.91      0.89      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_sel = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
    "                                    class_weight='balanced')\n",
    "classifier_sel.fit(X_train_sel, y_train)\n",
    "\n",
    "predictions_sel = classifier_sel.predict(X_dev_sel)\n",
    "print(classification_report(y_dev, predictions_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81       900\n",
      "           1       0.22      0.86      0.35       104\n",
      "           2       0.86      0.87      0.87      1020\n",
      "           3       0.58      0.83      0.68       383\n",
      "           4       0.95      0.80      0.87      2593\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.69      0.83      0.72      5000\n",
      "weighted avg       0.87      0.81      0.83      5000\n",
      "\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       900\n",
      "           1       0.29      0.88      0.44       104\n",
      "           2       0.90      0.89      0.89      1020\n",
      "           3       0.63      0.87      0.73       383\n",
      "           4       0.95      0.84      0.89      2593\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.72      0.86      0.76      5000\n",
      "weighted avg       0.88      0.85      0.86      5000\n",
      "\n",
      "\n",
      "500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       900\n",
      "           1       0.32      0.87      0.47       104\n",
      "           2       0.90      0.90      0.90      1020\n",
      "           3       0.66      0.89      0.76       383\n",
      "           4       0.96      0.86      0.91      2593\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.74      0.87      0.78      5000\n",
      "weighted avg       0.89      0.86      0.87      5000\n",
      "\n",
      "\n",
      "1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       900\n",
      "           1       0.38      0.85      0.52       104\n",
      "           2       0.91      0.91      0.91      1020\n",
      "           3       0.69      0.92      0.79       383\n",
      "           4       0.96      0.88      0.92      2593\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.76      0.88      0.80      5000\n",
      "weighted avg       0.90      0.88      0.89      5000\n",
      "\n",
      "\n",
      "1500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       900\n",
      "           1       0.41      0.86      0.56       104\n",
      "           2       0.91      0.92      0.92      1020\n",
      "           3       0.71      0.92      0.80       383\n",
      "           4       0.96      0.89      0.92      2593\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.78      0.89      0.81      5000\n",
      "weighted avg       0.91      0.89      0.89      5000\n",
      "\n",
      "\n",
      "2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87       900\n",
      "           1       0.42      0.84      0.56       104\n",
      "           2       0.91      0.92      0.92      1020\n",
      "           3       0.72      0.92      0.81       383\n",
      "           4       0.96      0.90      0.93      2593\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.78      0.88      0.82      5000\n",
      "weighted avg       0.91      0.89      0.90      5000\n",
      "\n",
      "\n",
      "2500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       900\n",
      "           1       0.42      0.84      0.56       104\n",
      "           2       0.92      0.92      0.92      1020\n",
      "           3       0.73      0.92      0.81       383\n",
      "           4       0.96      0.90      0.93      2593\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.78      0.88      0.82      5000\n",
      "weighted avg       0.91      0.89      0.90      5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "for k in [100, 300, 500, 1000, 1500, 2000, 2500]:\n",
    "    print(k)\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "\n",
    "    X_train_dim = svd.fit_transform(X_train_sel)\n",
    "    X_dev_dim = svd.transform(X_dev_sel)\n",
    "    X_test_dim = svd.transform(X_test_sel)\n",
    "\n",
    "    classifier_dim = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
    "                                        class_weight='balanced')\n",
    "    classifier_dim.fit(X_train_dim, y_train)\n",
    "\n",
    "    predictions_dim = classifier_dim.predict(X_dev_dim)\n",
    "    print(classification_report(y_dev, predictions_dim))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def bootstrap_sample(system1, system2, gold, samples=1000, score=f1_score, average='micro'):\n",
    "    \"\"\"\n",
    "    compute the proportion of times the performance difference of the \n",
    "    two systems on a subsample is significantly different from the \n",
    "    performance on the entire sample\n",
    "    \"\"\"\n",
    "    N = len(gold) # number of instances\n",
    "    \n",
    "    # make sure the two systems have the same number of samples\n",
    "    assert len(system1) == N and len(system2) == N, 'samples have different lengths'\n",
    "\n",
    "    # compute performance score on entire sample\n",
    "    base_score1 = score(gold, system1, average=average)\n",
    "    base_score2 = score(gold, system2, average=average)\n",
    "\n",
    "    # switch systems if system2 is better\n",
    "    if base_score2 > base_score1:\n",
    "        system1, system2 = system2, system1\n",
    "        base_score1, base_score2 = base_score2, base_score1\n",
    "    \n",
    "    # compute the difference\n",
    "    basedelta = base_score1 - base_score2\n",
    "    assert basedelta > 0, 'Wrong system first, system1 needs to be better!'\n",
    "\n",
    "    system1 = np.array(system1)\n",
    "    system2 = np.array(system2)\n",
    "    gold = np.array(gold)\n",
    "\n",
    "    p = 0\n",
    "    deltas = []\n",
    "    for i in range(samples):\n",
    "        # select a subsample, with replacement\n",
    "        sample = np.random.choice(N, size=N, replace=True)\n",
    "\n",
    "        # collect data corresponding to subsample\n",
    "        sample1 = system1[sample]\n",
    "        sample2 = system2[sample]\n",
    "        gold_sample = gold[sample]\n",
    "\n",
    "        # compute scores on subsample\n",
    "        sample_score1 = score(gold_sample, sample1, average=average)\n",
    "        sample_score2 = score(gold_sample, sample2, average=average)\n",
    "        sample_delta = sample_score1 - sample_score2\n",
    "\n",
    "        # check whether the observed sample difference is at least \n",
    "        # twice as large as the base difference\n",
    "        if sample_delta > 2*basedelta:\n",
    "            p += 1\n",
    "        deltas.append(sample_delta)\n",
    "                \n",
    "    return p/samples, deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 True\n"
     ]
    }
   ],
   "source": [
    "p_value, deltas = bootstrap_sample(predictions, dumb_predictions, y_dev)\n",
    "print(p_value, p_value < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5186 0.9103999999999999\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, dumb_predictions, average='micro'), f1_score(y_dev, predictions_c_dev, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12b3c1c18>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.Series(deltas).plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
