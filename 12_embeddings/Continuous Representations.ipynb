{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word Representations\n",
    "\n",
    "## *\"I know words. I have the best words!\"*\n",
    "    - Noam Chomsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dense Distributed Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/reviews.full.tsv', sep='\\t', nrows=100000)\n",
    "documents = df.text.tolist()\n",
    "print(documents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Word embeddings with `Word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import FAST_VERSION\n",
    "\n",
    "corpus = [document.split() for document in documents]\n",
    "\n",
    "# initialize model\n",
    "w2v_model = Word2Vec(size=100,\n",
    "                     window=15,\n",
    "                     sample=0.0001,\n",
    "                     iter=200,\n",
    "                     negative=5, \n",
    "                     min_count=100,\n",
    "                     workers=-1, \n",
    "                     hs=0\n",
    ")\n",
    "\n",
    "w2v_model.build_vocab(corpus)\n",
    "\n",
    "w2v_model.train(corpus, \n",
    "                total_examples=w2v_model.corpus_count, \n",
    "                epochs=w2v_model.epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can use the embeddings of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv['delivery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['delivery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# birthday - present + husband => birthday:present as husband:?\n",
    "w2v_model.wv.most_similar(positive=['dog', 'husband'], negative=['cat'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "word1 = \"Cheapest\"\n",
    "word2 = \"friendly\"\n",
    "\n",
    "# retrieve the actual vector\n",
    "# print(w2v_model.wv[word1])\n",
    "\n",
    "# compare\n",
    "print(w2v_model.wv.similarity(word1, word2))\n",
    "\n",
    "# get the 3 most similar words\n",
    "print(w2v_model.wv.most_similar(word1, topn=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Exercise\n",
    "Use `spacy` to restrict the words in the tweets to *content words*, i.e., nouns, verbs, and adjectives. Transform the words to lower case and add the POS with an underderscore. E.g.:\n",
    "\n",
    "`love_VERB old-fashioneds_NOUN`\n",
    "\n",
    "This also allows us to distinguish between homographs, i.e., words that are written the same, but belong to different word classes, e.g., *love* in \"I **love** old-fashioneds\" vs. \"He felt so sick, it must have been **love**\".\n",
    "\n",
    "\n",
    "Make sure to exclude sentences that contain none of the above.\n",
    "\n",
    "Write the resulting corpus to a variable called `word_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the `Word2vec` model from above on the new data set and test the words out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Train 4 more `Word2vec` models and average the resulting embedding matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Document embeddings with `Doc2Vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import FAST_VERSION\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for row in df.iterrows():\n",
    "    label = row[1].score\n",
    "    text = row[1].text\n",
    "    corpus.append(TaggedDocument(words=text.split(), tags=[str(label)]))\n",
    "\n",
    "print('done')\n",
    "d2v_model = Doc2Vec(vector_size=100, \n",
    "                    window=15,\n",
    "                    hs=0,\n",
    "                    sample=0.000001,\n",
    "                    negative=5,\n",
    "                    min_count=100,\n",
    "                    workers=-1,\n",
    "                    epochs=500,\n",
    "                    dm=0, \n",
    "                    dbow_words=1)\n",
    "\n",
    "d2v_model.build_vocab(corpus)\n",
    "\n",
    "d2v_model.train(corpus, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now look at the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.docvecs.doctags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_doc = '1'\n",
    "\n",
    "similar_docs = d2v_model.docvecs.most_similar(target_doc, topn=5)\n",
    "print(similar_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "What are the 10 most similar ***words*** to each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "d2v_model.wv.most_similar([d2v_model.docvecs['3']], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
